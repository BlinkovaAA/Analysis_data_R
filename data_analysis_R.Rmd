---

---


## Получение данных
```{r echo=FALSE, message = FALSE, warning=FALSE}
setwd("...")
library(data.table)
library(ggplot2)
library(dplyr)
library(datasets)
library(tidyverse)
library(gvlma)
library(trafo)
library(lmtest)
```
### Пример получившихся данных
```{r echo=FALSE, message = FALSE, warning=FALSE}

set.seed(2002)

data_1 <- rnorm(100, mean = 10, sd = 2)
data_2 <- runif(100, min = 0, max = 30)

e1 <- rnorm(100, mean = 0, sd = 1)
e2 <- rnorm(100, mean = 0, sd = 2)

data_3 <- 3*data_1+6+e1
data_4 <- round(3*data_2-6+e2, digits = 0)%%2

data_new <- data.frame(data_1, data_2, data_3, data_4)

lines_na <- sample(x = 1:nrow(data_new), 
                     size = nrow(data_new)*0.05, 
                     replace = FALSE)

for (line in lines_na) {
  
  data_new[line, sample(1:ncol(data_new), 
                             size = sample(1:3, 1, replace = FALSE))] <- NA
}

head(data_new)
```

### Результат предобработки данных
```{r echo=FALSE, message = FALSE, warning=FALSE}
summary(data_new)

data_new <- data_new[complete.cases(data_new), ]

cat("Осталось значений: ", nrow(data_new), "\nКоличество строк с отсутствующими значениями: ", sum(!complete.cases(data_new)))
```

Вывод: Из результатов предобработки видим, что все значения после запятой имеют одинаковое количество чисел. А также остаток значений после предобработки стал на 5 меньше. Это значит, что в наборе данных было 5 нулевых строк, которые впоследствии были удалены.


## Визуализация данных
### Боксплот
Построим боксплот для всех переменных в наборе данных data_new. data_1, data_2, data_3 соответственно.
Для data_4 боксплот строить не будем, т.к его вид и так изначально ясен, значения этой переменной состоят только из 0 и 1.
```{r echo=FALSE, message = FALSE, warning=FALSE}
data_new %>% 
  select(data_1) %>% 
  ggplot(aes(y = data_1)) +
  geom_boxplot() +
  labs(x = "", y = "data_1",
       title = "Боксплот для переменной data_1") +
    theme(axis.text.x = element_blank())

data_new %>% 
  select(data_2) %>% 
  ggplot(aes(y = data_2)) +
  geom_boxplot() +
  labs(x = "", y = "data_2",
       title = "Боксплот для переменной data_2") +
    theme(axis.text.x = element_blank())

data_new %>% 
  select(data_3) %>% 
  ggplot(aes(y = data_3)) +
  geom_boxplot() +
  labs(x = "", y = "data_3",
       title = "Боксплот для переменной data_3") +
    theme(axis.text.x = element_blank())
```


Вывод: Данный вид графиков построен для того, чтобы быстро оценить данные в выборке. Так как основными характеристиками любой числовой выборки являются: медиана, размах и др.,данный тип диаграмм позволяет быстро посчитать медиану(обозначена черной линией на рисунке), размах, верхний квартиль (верхняя сторона прямоугольника), нижний квартиль (нижняя сторона прямоугольника), максимальное значение, минимальное значение, а также "выброс" (точка на диаграмме).


## QQ plot
Построим QQ plot для каждой из переменных.
```{r echo=FALSE, message = FALSE, warning=FALSE}
qqnorm(data_1, main = 'data_1', xlab = 'Теоретический квантиль', ylab = 'Значения', col = 'red')
qqline(data_1)

qqnorm(data_2, main = 'data_2', xlab = 'Теоретический квантиль', ylab = 'Значения', col = 'pink')
qqline(data_2)

qqnorm(data_3, main = 'data_3', xlab = 'Теоретический квантиль', ylab = 'Значения', col = 'blue')
qqline(data_3)
```

Вывод: График "квантиль-квантиль", в сокращении QQ, в основном используют для того, чтобы определить соответствуют ли значения какому либо распределению. После построения графиков переменных data_1, data_2, data_3, мы видим, что отклонение от прямой на некоторых участках незначительное, а на некоторых визуально заметное, отсюда можно сделать вывод о том, что выборка имеет выбросы. 

## Диаграмма рассеивания
Постороим диаграммы рассеивания для пар значений
```{r echo=FALSE, message = FALSE, warning=FALSE}
data_new %>% 
  select(data_1, data_2) %>% 
  ggplot(aes(x = data_1, y = data_2)) +
  geom_point() +
  labs(x = "data_1", 
       y = "data_2", title = "Диаграмма рассеивания data_2 от data_1")

data_new %>% 
  select(data_1, data_3) %>% 
  ggplot(aes(x = data_1, y = data_3)) +
  geom_point() +
  labs(x = "data_1", 
       y = "data_3", title = "Диаграмма рассеивания data_3 от data_1")

data_new %>% 
  select(data_1, data_4) %>% 
  ggplot(aes(x = data_1, y = data_4)) +
  geom_point() +
  labs(x = "data_1", 
       y = "data_4", title = "Диаграмма рассеивания data_4 от data_1")

data_new %>% 
  select(data_3, data_2) %>% 
  ggplot(aes(x = data_2, y = data_3)) +
  geom_point() +
  labs(x = "data_2", 
       y = "data_3", title = "Диаграмма рассеивания data_3 от data_2")

data_new %>% 
  select(data_4, data_2) %>% 
  ggplot(aes(x = data_2, y = data_4)) +
  geom_point() +
  labs(x = "data_2", 
       y = "data_4", title = "Диаграмма рассеивания data_4 от data_2")

data_new %>% 
  select(data_3, data_4) %>% 
  ggplot(aes(x = data_3, y = data_4)) +
  geom_point() +
  labs(x = "data_3", 
       y = "data_4", title = "Диаграмма рассеивания data_4 от data_3")
```

Вывод: Диаграмма рассеивания применяется для выявления зависимости одной переменной величины от другой. Из построенных графиков можно сделать вывод о том, что переменные data_3 и data_1 зависят друг от друга.

## Построение модели линейной регрессии

Перед тем как перейти к построению модели линейной регрессии обратимся к пункту "Визуализация данных" и посмотрим на графики БОКСПЛОТ. Это позволит нам увидеть выбросы данной выборки. Далее проведем корреляционный анализ.  Теоретически корреляция между независимыми переменными должна быть нулевой. На практике мы ожидаем, что корреляция между независимыми переменными слабая или вообще отсутствует, и нас это устраивает.

### Корреляционная матрица


```{r echo=FALSE, message = FALSE, warning=FALSE}
data_new %>% 
  select(data_1, data_2, data_3, data_4) %>% 
  cor()
```

Одним из способов количественной оценки этой взаимосвязи является использование коэффициента корреляции Пирсона , который является мерой линейной связи между двумя переменными . Он имеет значение от -1 до 1, где:

1) -1 указывает на совершенно отрицательную линейную корреляцию между двумя переменными
2) 0 указывает на отсутствие линейной корреляции между двумя переменными
3) 1 указывает на совершенно положительную линейную корреляцию между двумя переменными.

Из корреляционной матрицы видно, что переменные data_1 и data_3 имеют положительную линейную корреляцию, т.к их значение приближенно к 1. 

### Построение модели линейной регрессии

Для построения линейной регрессии мы будем использовать lm() функцию.

```{r echo=FALSE, message = FALSE, warning=FALSE}
model_1 <- lm(data_3~data_1, data = data_new)
summary(model_1)
```
Из отчета видно, что значение p-value: < 2.2e-16, это значит - переменные data_1 и data_3 действительно значимы, т.к отвергается нулевая гипотеза о равенстве коэффициентов нулю и об одновременной незначимости коэффициентов модели.

Возьмем, для примера, модель линейной регрессии для переменных data_1 и data_2, корреляционная матрица указывает на совершенно отрицательную линейную корреляцию между двумя переменными. А значит нулевая гипотеза подтвердится. 

```{r echo=FALSE, message = FALSE, warning=FALSE}
model_2 <- lm(data_1~data_2, data = data_new)
summary(model_2)
```

Утверждение истинно, это следует из значения переменной p-value.

## Прогнозирование значений с помощью модели
```{r echo=FALSE, message = FALSE, warning=FALSE}
plot(x=predict(model_1), y=data_new$data_3,
 xlab='Прогнозируемые значения',
 ylab='Реальные значения',
 main='График сравнения прогнозируемые и реальных значений функции')
abline(a = 0 , b = 1 )
```

Зависимость подтвердилась. Полученная модель является точной, что еще раз подтверждает выводы, полученные по итогам оценки формальных критериев модели линейной регрессии.

## Проверка соблюдения предпосылок модели.

### Проверка на гетероскедастичность

Cтатистическое свойство данных, которое означает, что изменчивость (или дисперсия) ошибок модели однородна по всем значениям независимой переменной. Разброс ошибок остается примерно постоянным вдоль всех уровней независимой переменной.

```{r echo=FALSE, message = FALSE, warning=FALSE}
model_3 <- lm( data_3 ~ data_1, data = data_new)
bptest(model_3)
```

Вывод: p-value = 0.09407 больше уровня значимости 0.05, значит значения гомоскедастичны - ошибка предсказания модели одинаково точна как для небольших, так и для больших значений независимой переменной.

### Проверка по теореме Гаусса - Маркова

 Далее для проверки воспользуемся теоремой Гаусса- Маркова, которая рассматривает зависимость двух параметров. Для этого должны выполняться следующие условия: 
1) Модель линейна
2) Все величины первой переменной не равны между собой
3) Разброс ошибок всегда одинаковый
4) Связь между значениями параметра в любых двух ситуациях отсутствует.
Выполнимость условий будем проверять для data_1 и data_3.
Выполнимость данных условий можно проверить с помощью специальной функции gvlma()

```{r echo=FALSE, message = FALSE, warning=FALSE}
conditionsGM <- gvlma(model_1)
conditionsGM
```

Из результатов видно, что предположение о нормальности распределения (Skewness, Kurtosis), однородности дисперсии остатков и отсутствия в них корреляции (Heteroscedasticity), результаты теста на соответствие формы связи (Link Function)- выполняются и являются приемлемыми. Модель следует считать значимой.


## Вывод
В данной работе были рассмотрены основные виды визуализации данных на языке программирования R.  Были проанализированы возможности и преимущества. Исследование показало, что язык R предоставляет богатый набор инструментов для визуализации данных,  позволяя создавать информативные графики.
